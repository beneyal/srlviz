{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "from collections import Counter, defaultdict, namedtuple\n",
    "from itertools import groupby\n",
    "from multiprocessing import cpu_count\n",
    "from operator import itemgetter\n",
    "from string import punctuation\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from conllu.parser import parse as conllu_parse\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of sentences (after filtering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [00:31<00:00, 979.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23062193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sents = 0\n",
    "path = 'aligned_sents/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        sents += len(json.load(f))\n",
    "print(sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:59<00:00, 259.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 1945\n",
      "English tokens: 194217249\n",
      "Hebrew tokens: 188375525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "en_tokens = 0\n",
    "he_tokens = 0\n",
    "errors = 0\n",
    "path = 'fastalign/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                en, he = line.strip().split(' ||| ')\n",
    "                en_tokens += len(en.strip().split())\n",
    "                he_tokens += len(he.strip().split())\n",
    "            except:\n",
    "                errors += 1\n",
    "print('Errors:', errors)\n",
    "print('English tokens:', en_tokens)\n",
    "print('Hebrew tokens:', he_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of English sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:02<00:00, 491.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.452778233188838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sents = 23062193\n",
    "lengths = 0\n",
    "path = 'aligned_sents/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for sent in json.load(f):\n",
    "            lengths += len(sent['en'].strip().split())\n",
    "print(lengths / sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of Hebrew sentences - before segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:03<00:00, 486.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.126847477167501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sents = 23062193\n",
    "lengths = 0\n",
    "path = 'aligned_sents/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for sent in json.load(f):\n",
    "            lengths += len(sent['he'].strip().split())\n",
    "print(lengths / sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average length of Hebrew sentences - after segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:20<00:00, 381.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.168153176066127\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sents = 23062193\n",
    "lengths = 0\n",
    "path = 'fastalign/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, he = line.split(' ||| ')\n",
    "            lengths += len(he.strip().split())\n",
    "print(lengths / sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of English tokens/types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:10<00:00, 439.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 148815217\n",
      "Types: 1540672\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "path = 'aligned_sents/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for sent in json.load(f):\n",
    "            tokens.extend(sent['en'].strip().split())\n",
    "print('Tokens:', len(tokens))\n",
    "print('Types:', len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Hebrew tokens/types - before segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:06<00:00, 467.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 118236346\n",
      "Types: 2468583\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "path = 'aligned_sents/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for sent in json.load(f):\n",
    "            tokens.extend(sent['he'].strip().split())\n",
    "print('Tokens:', len(tokens))\n",
    "print('Types:', len(set(tokens)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of Hebrew tokens/types - after segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:25<00:00, 363.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: 188375525\n",
      "Types: 894759\n"
     ]
    }
   ],
   "source": [
    "tokens = []\n",
    "path = 'fastalign/'\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            _, he = line.split(' ||| ')\n",
    "            tokens.extend(he.strip().split())\n",
    "print('Tokens:', len(tokens))\n",
    "print('Types:', len(set(tokens)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "570142"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = Counter(tokens)\n",
    "len([(word, count) for word, count in c.items() if count == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Node = namedtuple('Node', ['token', 'distance'])\n",
    "\n",
    "\n",
    "def parse_tree_depth(sentence):\n",
    "    root = [t for t in sentence if t['head'] == 0][0]\n",
    "    root = Node(root, 0)\n",
    "    visited, stack = [], [root]\n",
    "    while stack:\n",
    "        node = stack.pop()\n",
    "        if node not in visited:\n",
    "            visited.append(node)\n",
    "            stack.extend([Node(t, node.distance + 1) for t in sentence if t['head'] == node.token['id']])\n",
    "    return max(visited, key=itemgetter(1)).distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Hebrew parse tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [4:58:36<00:00,  1.72it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.956006308680185\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'hebrew_parsed/'\n",
    "sents_count = 23062193\n",
    "depths_count = 0\n",
    "for h in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, h), encoding='utf-8') as f:\n",
    "        sents = conllu_parse(f.read())\n",
    "        for sent in sents:\n",
    "            depths_count += parse_tree_depth(sent)\n",
    "print(depths_count / sents_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average English parse tree depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [3:48:33<00:00,  2.25it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.441202621103726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'english_parsed/'\n",
    "sents_count = 23062193\n",
    "depths_count = 0\n",
    "for h in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, h), encoding='utf-8') as f:\n",
    "        sents = conllu_parse(f.read())\n",
    "        for sent in sents:\n",
    "            depths_count += parse_tree_depth(sent)\n",
    "print(depths_count / sents_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English-Hebrew ratio - before segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [01:43<00:00, 297.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.328704602746318\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'aligned_sents/'\n",
    "ratios = 0\n",
    "sents = 23062193\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for sent in json.load(f):\n",
    "            en = len(sent['en'].strip().split())\n",
    "            he = len(sent['he'].strip().split())\n",
    "            if en and he:\n",
    "                ratios += en / he\n",
    "print(ratios / sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English-Hebrew ratio - after segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30883/30883 [02:07<00:00, 242.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors: 1945\n",
      "1.1205079794412722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'fastalign/'\n",
    "ratios = 0\n",
    "errors = 0\n",
    "sents = 23062193\n",
    "for sub in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, sub), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            try:\n",
    "                en, he = line.strip().split(' ||| ')\n",
    "                en = len(en.strip().split())\n",
    "                he = len(he.strip().split())\n",
    "                if en and he:\n",
    "                    ratios += en / he\n",
    "            except:\n",
    "                errors += 1\n",
    "print('Errors:', errors)\n",
    "print(ratios / sents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average number of Hebrew words aligned to English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [13:07<00:00, 39.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2506758527707749\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'fastalign_outputs/'\n",
    "en_words = 0\n",
    "he_words = 0\n",
    "for f_alignment in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, f_alignment), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            pairs = line.strip().split()\n",
    "            pairs = sorted([tuple(map(int, p.split('-'))) for p in pairs])\n",
    "            for _, g in groupby(pairs, key=itemgetter(0)):\n",
    "                en_words += 1\n",
    "                he_words += len(list(g))\n",
    "print(he_words / en_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of English-Hebrew word pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [00:36<00:00, 840.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "181765009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'fastalign_outputs/'\n",
    "pairs = 0\n",
    "for f_alignment in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, f_alignment), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            pairs += len(line.strip().split())\n",
    "            \n",
    "print(pairs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fast_align Pair Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [13:30<00:00, 38.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-0: 0\n",
      "1-1: 115554782\n",
      "1-n: 29778646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "path = 'fastalign_outputs/'\n",
    "one_to_zero = 0\n",
    "one_to_one = 0\n",
    "one_to_many = 0\n",
    "for f_alignment in tqdm(os.listdir(path)):\n",
    "    with open(os.path.join(path, f_alignment), encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            pairs = line.strip().split()\n",
    "            pairs = sorted([tuple(map(int, p.split('-'))) for p in pairs])\n",
    "            for _, g in groupby(pairs, key=itemgetter(0)):\n",
    "                length = len(list(g))\n",
    "                if length == 0:\n",
    "                    one_to_zero += 1\n",
    "                elif length == 1:\n",
    "                    one_to_one += 1\n",
    "                else:\n",
    "                    one_to_many += 1\n",
    "print('1-0:', one_to_zero)\n",
    "print('1-1:', one_to_one)\n",
    "print('1-n:', one_to_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [35:38<00:00, 14.39it/s]\n"
     ]
    }
   ],
   "source": [
    "path1 = 'fastalign_outputs/'  # has less files\n",
    "path2 = 'fastalign/'\n",
    "errors = 0\n",
    "word_pairs = Counter()\n",
    "for sub in tqdm(os.listdir(path1)):\n",
    "    with open(os.path.join(path1, sub), encoding='utf-8') as f1, open(os.path.join(path2, sub), encoding='utf-8') as f2:\n",
    "        for line1, line2 in zip(f1, f2):\n",
    "            pairs = line1.strip().split()\n",
    "            pairs = sorted([tuple(map(int, p.split('-'))) for p in pairs])\n",
    "            try:\n",
    "                en_sent, he_sent = line2.strip().split(' ||| ')\n",
    "                en_words = en_sent.split()\n",
    "                he_words = he_sent.split()\n",
    "                for i, js in groupby(pairs, key=itemgetter(0)):\n",
    "                    js = list(js)\n",
    "                    if len(js) == 1:\n",
    "                        j = js[0][1]\n",
    "                        word_pairs.update([(en_words[i].lower(), he_words[j].lower())])\n",
    "            except:\n",
    "                errors += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7530172"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ispunct(s):\n",
    "    return all([c in punctuation for c in s])\n",
    "\n",
    "keys = list(word_pairs)\n",
    "for k in keys:\n",
    "    if ispunct(k[0]):\n",
    "        word_pairs.pop(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7443214"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('i', 'אני'), 2946217),\n",
       " (('the', 'ה'), 2148227),\n",
       " (('you', 'אתה'), 2086108),\n",
       " (('and', 'ו'), 1565287),\n",
       " ((\"n't\", 'לא'), 1212902),\n",
       " (('it', 'זה'), 1119071),\n",
       " (('what', 'מה'), 1013666),\n",
       " (('me', 'אני'), 790374),\n",
       " (('he', 'הוא'), 787565),\n",
       " (('you', 'את'), 695642),\n",
       " (('not', 'לא'), 687369),\n",
       " (('to', 'ל'), 680021),\n",
       " (('that', 'זה'), 640604),\n",
       " (('in', 'ב'), 622867),\n",
       " (('but', 'אבל'), 550264),\n",
       " (('no', 'לא'), 535962),\n",
       " (('we', 'אנחנו'), 516574),\n",
       " (('this', 'זה'), 450298),\n",
       " (('she', 'היא'), 417537),\n",
       " (('if', 'אם'), 413350),\n",
       " (('yeah', 'כן'), 382135),\n",
       " (('that', 'ש'), 341983),\n",
       " (('they', 'הם'), 335973),\n",
       " (('know', 'יודע'), 331036),\n",
       " (('with', 'עם'), 312677),\n",
       " (('him', 'הוא'), 278949),\n",
       " (('here', 'כאן'), 275220),\n",
       " (('so', 'אז'), 274284),\n",
       " (('to', 'את'), 272781),\n",
       " (('of', 'של'), 260677),\n",
       " ((\"'s\", 'ה'), 260029),\n",
       " (('was', 'היה'), 257920),\n",
       " (('now', 'עכשיו'), 251554),\n",
       " ((\"'m\", 'אני'), 250630),\n",
       " (('want', 'רוצה'), 237890),\n",
       " (('for', 'ל'), 222461),\n",
       " (('her', 'היא'), 214870),\n",
       " (('just', 'רק'), 213826),\n",
       " (('you', 'ש'), 208257),\n",
       " (('a', 'ל'), 208167),\n",
       " (('all', 'כל'), 202317),\n",
       " (('about', 'על'), 189268),\n",
       " (('hey', 'היי'), 182442),\n",
       " (('yes', 'כן'), 182307),\n",
       " (('how', 'איך'), 178151),\n",
       " (('on', 'על'), 175662),\n",
       " (('or', 'או'), 173545),\n",
       " (('why', 'למה'), 171447),\n",
       " (('like', 'כמו'), 170821),\n",
       " (('something', 'משהו'), 162026),\n",
       " (('on', 'ב'), 161658),\n",
       " (('from', 'מ'), 161388),\n",
       " (('know', 'יודעת'), 161035),\n",
       " (('i', 'ש'), 160645),\n",
       " (('at', 'ב'), 157754),\n",
       " (('us', 'אנחנו'), 157246),\n",
       " (('just', 'פשוט'), 148414),\n",
       " (('when', 'כש'), 147984),\n",
       " (('there', 'שם'), 144476),\n",
       " (('who', 'מי'), 140717),\n",
       " (('can', 'יכול'), 139269),\n",
       " ((\"'s\", 'של'), 137111),\n",
       " (('good', 'טוב'), 129628),\n",
       " (('one', 'אחד'), 127327),\n",
       " (('have', 'ל'), 124573),\n",
       " (('be', 'להיות'), 123280),\n",
       " (('of', 'מ'), 123100),\n",
       " (('of', 'ה'), 119247),\n",
       " (('do', 'לעשות'), 115003),\n",
       " (('a', 'ב'), 113703),\n",
       " (('you', 'אתם'), 113492),\n",
       " (('then', 'אז'), 111805),\n",
       " (('do', 'אל'), 109977),\n",
       " (('your', 'ה'), 108864),\n",
       " (('time', 'זמן'), 108242),\n",
       " (('where', 'איפה'), 106209),\n",
       " (('maybe', 'אולי'), 105225),\n",
       " (('it', 'הוא'), 104515),\n",
       " (('is', 'הוא'), 103693),\n",
       " (('really', 'באמת'), 102783),\n",
       " (('this', 'ה'), 100605),\n",
       " (('people', 'אנשים'), 99890),\n",
       " (('there', 'יש'), 98986),\n",
       " (('right', 'נכון'), 98271),\n",
       " (('thank', 'תודה'), 93555),\n",
       " (('is', 'זה'), 92429),\n",
       " (('for', 'בשביל'), 91440),\n",
       " (('is', 'ה'), 88542),\n",
       " (('them', 'הם'), 86133),\n",
       " (('we', 'ש'), 83421),\n",
       " (('well', 'ובכן'), 83204),\n",
       " (('sorry', 'מצטער'), 82326),\n",
       " (('still', 'עדיין'), 81882),\n",
       " (('more', 'יותר'), 80167),\n",
       " (('that', 'ה'), 79326),\n",
       " (('okay', 'בסדר'), 77305),\n",
       " (('my', 'של'), 77204),\n",
       " (('because', 'כי'), 76979),\n",
       " (('to', 'ש'), 75354),\n",
       " (('my', 'ה'), 74950)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_pairs.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hebrew POS-tag distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [5:02:40<00:00,  1.70it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('NN', 22547152),\n",
       " ('yyDOT', 16887215),\n",
       " ('PRP', 13941874),\n",
       " ('VB', 13597524),\n",
       " ('RB', 12583894),\n",
       " ('DEF', 11563647),\n",
       " ('yyCM', 8760079),\n",
       " ('IN', 8416983),\n",
       " ('PREPOSITION', 8367178),\n",
       " ('S_PRN', 7772158),\n",
       " ('BN', 7747940),\n",
       " ('NNP', 6063453),\n",
       " ('JJ', 5936312),\n",
       " ('AT', 5147419),\n",
       " ('yyQM', 4641169),\n",
       " ('REL', 4569239),\n",
       " ('NNT', 3707301),\n",
       " ('QW', 2993666),\n",
       " ('CONJ', 2512398),\n",
       " ('CC', 2496745),\n",
       " ('POS', 2427657),\n",
       " ('COP', 2281502),\n",
       " ('MD', 2076368),\n",
       " ('DTT', 1722460),\n",
       " ('yyEXCL', 1630825),\n",
       " ('yyELPS', 1576157),\n",
       " ('CD', 1409611),\n",
       " ('EX', 1102323),\n",
       " ('INTJ', 999082),\n",
       " ('yyQUOT', 937301),\n",
       " ('TEMP', 256881),\n",
       " ('DT', 239988),\n",
       " ('TTL', 156193),\n",
       " ('CDT', 125870),\n",
       " ('yyCLN', 114823),\n",
       " ('P', 104586),\n",
       " ('JJT', 95604),\n",
       " ('yyRRB', 68302),\n",
       " ('NCD', 66348),\n",
       " ('yyLRB', 65762),\n",
       " ('BNT', 61648),\n",
       " ('ADVERB', 17573),\n",
       " ('yySCLN', 9912),\n",
       " ('NEG', 4606),\n",
       " ('NNPT', 85)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "he_postags = Counter()\n",
    "for file in tqdm(os.listdir('hebrew_parsed/')):\n",
    "    with open(os.path.join('hebrew_parsed/', file), encoding='utf-8') as f:\n",
    "        he_postags.update([token['upostag'] for sent in conllu_parse(f.read()) for token in sent])\n",
    "he_postags.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## English POS-tag distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [3:44:38<00:00,  2.28it/s]  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 22516525),\n",
       " ('PRP', 22277895),\n",
       " ('NN', 18757022),\n",
       " ('RB', 12305224),\n",
       " ('DT', 12266974),\n",
       " ('IN', 11678617),\n",
       " ('NNP', 10205478),\n",
       " ('VB', 10181014),\n",
       " (',', 9574190),\n",
       " ('VBP', 9174820),\n",
       " ('JJ', 6778558),\n",
       " ('VBZ', 5525697),\n",
       " ('VBD', 5140162),\n",
       " ('TO', 4127560),\n",
       " ('NNS', 4049763),\n",
       " ('VBG', 3274947),\n",
       " ('CC', 3248620),\n",
       " ('MD', 3129102),\n",
       " ('PRP$', 3091388),\n",
       " ('VBN', 2164050),\n",
       " ('UH', 2074193),\n",
       " ('WP', 1901387),\n",
       " (':', 1635039),\n",
       " ('WRB', 1419453),\n",
       " ('CD', 1340267),\n",
       " ('RP', 840481),\n",
       " ('POS', 667730),\n",
       " ('WDT', 574816),\n",
       " ('``', 453748),\n",
       " ('EX', 363680),\n",
       " (\"''\", 345117),\n",
       " ('JJR', 297976),\n",
       " ('JJS', 185180),\n",
       " ('PDT', 159843),\n",
       " ('RBR', 134683),\n",
       " ('-RRB-', 106620),\n",
       " ('-LRB-', 106609),\n",
       " ('NNPS', 101716),\n",
       " ('FW', 54365),\n",
       " ('#', 53198),\n",
       " ('$', 35715),\n",
       " ('RBS', 29242),\n",
       " ('WP$', 6547),\n",
       " ('LS', 6258),\n",
       " ('SYM', 50)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "en_postags = Counter()\n",
    "for file in tqdm(os.listdir('english_parsed/')):\n",
    "    with open(os.path.join('english_parsed/', file), encoding='utf-8') as f:\n",
    "        en_postags.update([token['upostag'] for sent in conllu_parse(f.read()) for token in sent])\n",
    "en_postags.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [20:37<00:00, 24.87it/s]\n"
     ]
    }
   ],
   "source": [
    "targets = Counter()\n",
    "sents_count = 0\n",
    "for f in tqdm(os.listdir('english_srl/')):\n",
    "    with open(os.path.join('english_srl/', f), encoding='utf-8') as j:\n",
    "        for line in j:\n",
    "            frames = json.loads(line)['frames']\n",
    "            sents_count += 1\n",
    "            for frame in frames:\n",
    "                targets.update([frame['target']['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average #frames/sentence: 2.3994585422700814\n",
      "Number of frames (targets): 55246362\n",
      "Number of unique targets: 784\n",
      "20 most common targets:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Intentionally_act', 2922780),\n",
       " ('Locative_relation', 2124853),\n",
       " ('Quantity', 1706189),\n",
       " ('Arriving', 1696957),\n",
       " ('Being_obligated', 1198687),\n",
       " ('Desirability', 1190368),\n",
       " ('Statement', 1161159),\n",
       " ('Capability', 1156961),\n",
       " ('Temporal_collocation', 1116567),\n",
       " ('Cardinal_numbers', 1080994),\n",
       " ('People', 1054872),\n",
       " ('Calendric_unit', 862375),\n",
       " ('Causation', 837578),\n",
       " ('Kinship', 803670),\n",
       " ('Certainty', 796327),\n",
       " ('Desiring', 713872),\n",
       " ('Relational_quantity', 665392),\n",
       " ('Awareness', 660211),\n",
       " ('Observable_body_parts', 627344),\n",
       " ('Becoming', 606179)]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Average #frames/sentence:', sum(targets.values()) / sents_count)\n",
    "print('Number of frames (targets):', sum(targets.values()))\n",
    "print('Number of unique targets:', len(targets.keys()))\n",
    "print('20 most common targets:')\n",
    "targets.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [21:54<00:00, 23.42it/s]\n"
     ]
    }
   ],
   "source": [
    "fes = Counter()\n",
    "sents_count = 0\n",
    "for f in tqdm(os.listdir('english_srl/')):\n",
    "    with open(os.path.join('english_srl/', f), encoding='utf-8') as j:\n",
    "        for line in j:\n",
    "            frames = json.loads(line)['frames']\n",
    "            sents_count += 1\n",
    "            for frame in frames:\n",
    "                for fe in frame['annotationSets'][0]['frameElements']:\n",
    "                    fes.update([fe['name']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average #FEs/sentence: 2.8115148325402077\n",
      "Number of FEs: 64733757\n",
      "Number of unique FEs: 661\n",
      "20 most common FEs:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Entity', 3891862),\n",
       " ('Agent', 3299307),\n",
       " ('Theme', 3048768),\n",
       " ('Cognizer', 2920899),\n",
       " ('Event', 2618780),\n",
       " ('Act', 1967112),\n",
       " ('Quantity', 1699100),\n",
       " ('Experiencer', 1677843),\n",
       " ('Goal', 1668385),\n",
       " ('Speaker', 1557612),\n",
       " ('Content', 1537237),\n",
       " ('Person', 1406459),\n",
       " ('Evaluee', 1404153),\n",
       " ('Message', 1270952),\n",
       " ('Ground', 1121609),\n",
       " ('Unit', 1094743),\n",
       " ('Responsible_party', 1079516),\n",
       " ('Number', 1069190),\n",
       " ('Phenomenon', 1009228),\n",
       " ('Locale', 816558)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Average #FEs/sentence:', sum(fes.values()) / sents_count)\n",
    "print('Number of FEs:', sum(fes.values()))\n",
    "print('Number of unique FEs:', len(fes.keys()))\n",
    "print('20 most common FEs:')\n",
    "fes.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30789/30789 [4:23:21<00:00,  1.95it/s]  \n"
     ]
    }
   ],
   "source": [
    "en_words = Counter()\n",
    "en_postags = Counter()\n",
    "for file in tqdm(os.listdir('english_parsed/')):\n",
    "    with open(os.path.join('english_parsed/', file), encoding='utf-8') as f:\n",
    "        sents = conllu_parse(f.read())\n",
    "        for sent in sents:\n",
    "            for token in sent:\n",
    "                en_words.update([token['form']])\n",
    "                en_postags.update([token['upostag']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of English words: 192361519\n",
      "Number of unique English words: 713666\n",
      "20 most common English words:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 15987895),\n",
       " (',', 9525720),\n",
       " ('I', 6030592),\n",
       " ('you', 4771733),\n",
       " ('?', 4675250),\n",
       " ('the', 4092004),\n",
       " ('to', 3576869),\n",
       " (\"'s\", 3249261),\n",
       " ('a', 2923023),\n",
       " (\"n't\", 2076183),\n",
       " ('it', 1988100),\n",
       " ('that', 1742936),\n",
       " ('!', 1734606),\n",
       " ('of', 1718093),\n",
       " ('You', 1588832),\n",
       " ('and', 1534830),\n",
       " ('do', 1510007),\n",
       " ('...', 1423630),\n",
       " ('is', 1418116),\n",
       " ('in', 1396204)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Number of English words:', sum(en_words.values()))\n",
    "print('Number of unique English words:', len(en_words.keys()))\n",
    "print('20 most common English words:')\n",
    "en_words.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common English POS tags:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('.', 22516525),\n",
       " ('PRP', 22277895),\n",
       " ('NN', 18757022),\n",
       " ('RB', 12305224),\n",
       " ('DT', 12266974),\n",
       " ('IN', 11678617),\n",
       " ('NNP', 10205478),\n",
       " ('VB', 10181014),\n",
       " (',', 9574190),\n",
       " ('VBP', 9174820),\n",
       " ('JJ', 6778558),\n",
       " ('VBZ', 5525697),\n",
       " ('VBD', 5140162),\n",
       " ('TO', 4127560),\n",
       " ('NNS', 4049763),\n",
       " ('VBG', 3274947),\n",
       " ('CC', 3248620),\n",
       " ('MD', 3129102),\n",
       " ('PRP$', 3091388),\n",
       " ('VBN', 2164050),\n",
       " ('UH', 2074193),\n",
       " ('WP', 1901387),\n",
       " (':', 1635039),\n",
       " ('WRB', 1419453),\n",
       " ('CD', 1340267),\n",
       " ('RP', 840481),\n",
       " ('POS', 667730),\n",
       " ('WDT', 574816),\n",
       " ('``', 453748),\n",
       " ('EX', 363680),\n",
       " (\"''\", 345117),\n",
       " ('JJR', 297976),\n",
       " ('JJS', 185180),\n",
       " ('PDT', 159843),\n",
       " ('RBR', 134683),\n",
       " ('-RRB-', 106620),\n",
       " ('-LRB-', 106609),\n",
       " ('NNPS', 101716),\n",
       " ('FW', 54365),\n",
       " ('#', 53198),\n",
       " ('$', 35715),\n",
       " ('RBS', 29242),\n",
       " ('WP$', 6547),\n",
       " ('LS', 6258),\n",
       " ('SYM', 50)]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Most common English POS tags:')\n",
    "en_postags.most_common()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
